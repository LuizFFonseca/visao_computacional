# %% [markdown]
# # Abordagem utilizando Aprendizagem Profunda (Deep Learning)

# %% [markdown]
## 1. Configuração do Ambiente e Dados

Diferente da abordagem clássica, que depende de características manuais (cor e estatística de pixel), utilizaremos uma Rede Neural Convolucional (CNN) moderna: o **YOLO (You Only Look Once)**, especificamente a versão 11.



[Image of YOLO architecture]

 
 **Por que YOLO?**
 * **Robustez:** Aprende padrões de textura e forma, não apenas cor.
 * **Contexto:** Analisa a imagem inteira de uma vez, diferenciando melhor o que é corrosão de fundos complexos (sujeira, pintura velha).
 * **Velocidade:** Otimizado para inferência em tempo real.
 
 O código abaixo verifica a disponibilidade de aceleração por GPU (essencial para o treino) e realiza o download automático do dataset via API do Kaggle.

# %%
# Verifica o hardware disponível (GPU NVIDIA é recomendada)
!nvidia-smi
!nvcc --version

# %%
# Download do Dataset
try:
    import kagglehub
except:
    %pip install kagglehub
    import kagglehub

# O kagglehub gerencia o cache e baixa a versão mais recente
path = kagglehub.dataset_download("wednesday233/corrosion-detect-dataset")
print("Caminho dos arquivos do dataset:", path)

# %%
# Instalação/Importação da biblioteca Ultralytics (YOLO)
try:
    from ultralytics import YOLO
except:
    !pip install ultralytics
    from ultralytics import YOLO

import yaml
import os
import pandas as pd
import matplotlib.pyplot as plt
import glob
import cv2
import math

# %% [markdown]
# ## 2. Estrutura de Diretórios e Configuração
# 
# Organizamos os diretórios de saída para salvar os pesos do modelo treinado e os logs de desempenho.

# %%
BASE_PATH = "dataset_yolo_final/"
SAVE_PATH = os.path.join(BASE_PATH, "corrosion_detect_yolo")

# Garante que o diretório de salvamento exista
os.makedirs(SAVE_PATH, exist_ok=True)

# %% [markdown]
# ### Configuração do Treinamento
# 
# Definimos os hiperparâmetros globais.
# 
# * **Épocas:** Quantas vezes o modelo verá o dataset completo.
# * **Batch Size:** Quantas imagens são processadas simultaneamente pela GPU.
# * **Img Size:** O YOLO redimensiona as imagens. 640x640 é o padrão de equilíbrio entre velocidade e precisão.

# %%
# Hiperparâmetros
TRAIN_EPOCH = 100  # Treino longo para convergência final
TUNE_EPOCH = 30    # Treino curto para busca de hiperparâmetros (Tuning)
BATCH_SIZE = 16    # Ajuste conforme a VRAM da GPU (16 é seguro para Colab/T4)
IM_SIZE = 640      # Resolução de entrada da rede
GPUS = [0]         # ID da GPU

# Caminho do arquivo de configuração dos dados (já deve estar formatado no padrão YOLO)
DATA_YAML = os.path.join(BASE_PATH, "data.yaml")

# %% [markdown]
# ## 3. Otimização de Hiperparâmetros (Hyperparameter Tuning)
# 
# Antes do treino definitivo, realizamos um **Tuning**. O YOLO possui dezenas de parâmetros (taxa de aprendizado, momentum, aumento de dados como rotação e mixup).
# 
# Em vez de usar os valores padrão, o método `.tune()` executa várias rodadas curtas testando combinações genéticas de parâmetros para maximizar a métrica de validação no nosso dataset específico de corrosão.

# %%
# Inicializa o modelo 'nano' (yolo11n) - Mais leve e rápido
model_name = "yolo11n.pt"
model = YOLO(model_name)

# Define o nome do projeto para salvar os logs
project = os.path.join(SAVE_PATH, model_name[:-3])

# Inicia o processo de Tuning
# degrees=0.45 -> Permite rotação de +/- 45 graus (útil pois corrosão não tem orientação fixa)
# flipud=0.5 -> Permite espelhamento vertical (navios não têm "cima/baixo" fixo para texturas)
model.tune(data=DATA_YAML, 
        epochs=TUNE_EPOCH, 
        imgsz=IM_SIZE, 
        iterations=30,   # Número de tentativas de combinações
        plots=False,
        save=False, 
        val=True,
        project=os.path.join(project, "tunning"),
        degrees=0.45,
        translate=0.2,
        flipud=0.5,
        fliplr=0.5,
        )

# %% [markdown]
# ## 4. Treinamento Definitivo
# 
# Após o tuning, carregamos os **melhores hiperparâmetros** encontrados e iniciamos o treinamento longo (`TRAIN_EPOCH`).
# 
# > **Nota:** É necessário limpar certas chaves do dicionário de configuração (como 'epochs') para evitar conflitos com os argumentos passados explicitamente para o método `.train()`.

# %%
# Reinicializa o modelo base
model = YOLO(model_name)

# Carrega os melhores parâmetros encontrados na etapa anterior
path_to_params = os.path.join(project, 'tunning/tune/best_hyperparameters.yaml')

with open(path_to_params, 'r') as f:
    best_params = yaml.safe_load(f)

# Limpeza e conversão de tipos dos parâmetros para evitar erros no PyTorch
if 'epochs' in best_params:
    del best_params['epochs'] # Remove para usarmos o TRAIN_EPOCH definido acima

if 'close_mosaic' in best_params:
    best_params['close_mosaic'] = int(best_params['close_mosaic'])

if 'warmup_epochs' in best_params:
    best_params['warmup_epochs'] = int(best_params['warmup_epochs'])

# Inicia o treinamento final
print(f"Iniciando treino com parâmetros otimizados...")
model.train(
    data=DATA_YAML,
    epochs=TRAIN_EPOCH,
    imgsz=IM_SIZE,
    project=project,
    **best_params  # Desempacota os parâmetros otimizados (lr0, momentum, etc.)
)

# %% [markdown]
# ## 5. Análise de Desempenho (Métricas)
# 
# Visualizamos a evolução do treinamento através das perdas (Losses) e da precisão (mAP).
# 
# * **Box Loss:** Erro na localização da caixa (o quão bem a caixa contorna a corrosão).
# * **Cls Loss (Class):** Erro na classificação (confundiu corrosão com fundo?).
# * **mAP50:** Precisão média considerando acerto se a sobreposição (IoU) for > 50%.

# %%
results_path = os.path.join(project, "train/results.csv")

# Leitura dos logs de treino
df = pd.read_csv(results_path)
df.columns = df.columns.str.strip() # Remove espaços extras nos nomes das colunas

# Plotagem das curvas de aprendizado
fig, axes = plt.subplots(2, 2, figsize=(15, 10))
epochs = df['epoch']

# 1. Box Loss
ax = axes[0, 0]
ax.plot(epochs, df['train/box_loss'], label='Train Box Loss', color='blue')
ax.plot(epochs, df['val/box_loss'], label='Val Box Loss', color='orange')
ax.set_title('Box Loss (Precisão da Localização)')
ax.set_xlabel('Época')
ax.set_ylabel('Loss')
ax.legend()
ax.grid(True, alpha=0.3)

# 2. Class Loss
ax = axes[0, 1]
ax.plot(epochs, df['train/cls_loss'], label='Train Cls Loss', color='blue')
ax.plot(epochs, df['val/cls_loss'], label='Val Cls Loss', color='orange')
ax.set_title('Class Loss (Precisão da Classe)')
ax.set_xlabel('Época')
ax.set_ylabel('Loss')
ax.legend()
ax.grid(True, alpha=0.3)

# 3. DFL Loss (Refinamento)
ax = axes[1, 0]
ax.plot(epochs, df['train/dfl_loss'], label='Train DFL Loss', color='blue')
ax.plot(epochs, df['val/dfl_loss'], label='Val DFL Loss', color='orange')
ax.set_title('DFL Loss (Focal Loss)')
ax.set_xlabel('Época')
ax.set_ylabel('Loss')
ax.legend()
ax.grid(True, alpha=0.3)

# 4. Métricas mAP (Mean Average Precision)
ax = axes[1, 1]
ax.plot(epochs, df['metrics/mAP50(B)'], label='mAP @ IoU=0.50', color='green')
ax.plot(epochs, df['metrics/mAP50-95(B)'], label='mAP @ IoU=0.50:0.95', color='purple')
ax.set_title('Métricas de Performance (mAP)')
ax.set_xlabel('Época')
ax.set_ylabel('Score')
ax.legend()
ax.grid(True, alpha=0.3)

plt.tight_layout()
plt.show()

# %% [markdown]
# ## 6. Teste e Visualização Comparativa
# 
# Nesta etapa final, realizamos a inferência no conjunto de teste. Para avaliar a qualidade visualmente, sobrepomos:
# 1.  **Ground Truth (Verde):** A marcação "correta" feita pelo humano (extraída dos `.txt`).
# 2.  **Predição (Cores do YOLO):** A caixa detectada pela IA.
# 
# Isso permite identificar *Falsos Positivos* (IA viu corrosão onde não tem) e *Falsos Negativos* (IA não viu a corrosão).

# %%
# Configuração dos caminhos de teste
images_path = "dataset_yolo_final/images/test/*.jpeg"
label_dir = "dataset_yolo_final/labels/test"

# Função para converter coordenadas normalizadas (YOLO) para pixels (OpenCV)
def get_box_coords(line, img_w, img_h):
    parts = line.strip().split()
    cls = int(parts[0])
    x_c, y_c, w, h = map(float, parts[1:])
    
    x1 = int((x_c - w / 2) * img_w)
    y1 = int((y_c - h / 2) * img_h)
    x2 = int((x_c + w / 2) * img_w)
    y2 = int((y_c + h / 2) * img_h)
    return x1, y1, x2, y2, cls

# Carrega lista de imagens
image_files = glob.glob(images_path)

# Carrega o melhor modelo treinado
model_path = os.path.join(project, "train/weights/best.pt")
model = YOLO(model_path)

# Configuração do Grid de Visualização
num_cols = 4
num_imgs = len(image_files)
num_rows = math.ceil(num_imgs / num_cols)

fig, axes = plt.subplots(num_rows, num_cols, figsize=(20, 5 * num_rows))

if num_imgs == 1: axes = [axes]
else: axes = axes.flatten()

print(f"Visualizando {num_imgs} imagens de teste com Ground Truth (Verde) vs. Predição...")

for i, img_file in enumerate(image_files):
    ax = axes[i]
    
    # 1. Inferência do Modelo
    results = model(img_file, conf=0.5, verbose=False)
    result = results[0]
    
    # Prepara a imagem base (cópia limpa em BGR)
    canvas = result.orig_img.copy()
    h, w, _ = canvas.shape
    
    # 2. Desenhar Ground Truth (Labels Reais)
    # Procuramos o arquivo .txt correspondente à imagem
    filename = os.path.basename(img_file)
    label_filename = os.path.splitext(filename)[0] + ".txt"
    label_path = os.path.join(label_dir, label_filename)
    
    if os.path.exists(label_path):
        with open(label_path, 'r') as f:
            lines = f.readlines()
            
        for line in lines:
            x1, y1, x2, y2, cls = get_box_coords(line, w, h)
            # Desenha retângulo VERDE para indicar a verdade absoluta (Dataset)
            cv2.rectangle(canvas, (x1, y1), (x2, y2), (0, 255, 0), 2)
    
    # 3. Desenhar Predições do Modelo
    # O método .plot() desenha as caixas preditas sobre a imagem fornecida (que já tem o GT)
    plot_img = result.plot(img=canvas)
    
    # 4. Exibição
    # Converte BGR (OpenCV) para RGB (Matplotlib)
    plot_img_rgb = cv2.cvtColor(plot_img, cv2.COLOR_BGR2RGB)
    
    ax.imshow(plot_img_rgb)
    ax.axis('off')
    ax.set_title(filename, fontsize=9)

# Limpeza de eixos vazios no grid
for j in range(i + 1, len(axes)):
    axes[j].axis('off')

plt.tight_layout()
plt.show()